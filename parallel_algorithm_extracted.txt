ProceedingsoftheCzech{JapaneseSeminarinAppliedMathematics2006
CzechTechnicalUniversityinPrague,September14-17,2006
pp.25{36
PARALLELALGORITHMFORNUMERICALSOLUTIONOFTHESHALLOW
WATEREQUATION
STANISLAVBRAND
1
Abstract.
Parallelprogrammingistheleadingtechniqueforacceleratingnumericalalgorithm.Thisarticle
dealswithparallelizationoftheprogramforsolvingtheshallowwaterequationin2D,representinganexampleofa
conservationlaw.Theequationissolvedby\002nitedifferenceand\002nitevolumemethodswithintheLax-Friedrichs,
Lax-WendroffandMacCormackscheme.ThealgorithmisparallelizedusingOpenMPandMPI.Theef\002ciency
measurementismademainlyonsystemswithsharedmemoryandthankstothesuf\002cientnumberofprocessors
therearesomeresultsofthemixedmodeprogrammingwhichusedbothOpenMPandMPI.
Keywords.
Conservationlaws,parallelprogramming,OpenMP,MPI,mixedmodeprogramming.
1.Introduction.
Thisarticlesummarizestheresultsofnumericalsolutionoftheshal-
lowwaterequation.The\002rstsectionshowsthederivationoftheone-dimensionalshallow
waterequationanddescribesthetwo-dimensionalshallowwatersystem.Thesecondsection
containsnumericalschemesused,intheparticular\002nitedifferenceand\002nitevolumevari-
antsofthewell-knownLax-Friedrichs,Lax-WendroffandMacCormackschemes.Thethird
sectiondescribesparallelization,thatwasmadeforimprovingprogramperformance.The
fourthand\002fthsectioncontainsseveralresultsofef\002ciencymeasurementandoftheproblem
solved.
2.Solvedproblem.
TheShallowwaterequationisaspecialcaseoftheEulerequations
describingwavemotioninshallowwater.Thetwo-dimensionalshallowwaterequationis
oftenusedfornumericalsimulationofnaturalriver\003ows.Forillustration,wederivetheone-
dimensionalshallowwaterequationwhichisalsooftenused.Considera\003uidinachannel
andassumethattheverticalvelocityinthe\003uidisnegligibleandthehorizontalvelocity
v
(
x;t
\
isconstantthroughanyverticalcrosssection.Forexample,smallaptitudewaveinthe
\003uidthatisshallowrelativetothewavelength.Weassumeanincompressible\003uid,where
thedensity
\275
isconstant.Ourvariableistheheightofwater
h
(
x;t
\
.Thetotalmassin
x
1
;x
2
attime
t
canbewrittenas
m
x
1
;x
2
=
R
x
2
x
1
\275h
(
x;t
\
x
.Verticalintegrationfrom
0
to
h
(
x;t
\
ofthemomentum
\275v
(
x;t
\
givesusthemass\003uxtobe
\275v
(
x;t
\
h
(
x;t
\
.Bydroppingoutthe
constant
\275
wegettheconservationofmassequationintheform
h
t
+(
vh
\
x
=0
:
(2.1\
NowwegettheconservationofmomentumfromtheEulerequation
(
\275hv
\
t
+(
\275hv
2
+
p
\
x
=0
:
(2.2\
Inourcase,thepressure
p
isdeterminedfromahydrostaticlawsayingthepressureat
depth
y
is
\275gy
,where
g
isthegravitationconstant.Integratingthisrelationverticallyfrom
y
=0
to
y
=
h
(
x;t
\
wegettheproperpressureterm
p
=
1
2
\275gh
2
.Usingthisin(2.2\and
pointingout
\275
gives
1
DepartmentofMathematics,FacultyofNuclearSciencesandPhysicalEngineering,CzechTechnicalUniver-
sity,Prague.
25

z
x
b(x,y)
y
h(x,y)

26
S.Brand
F
IG
.2.1
.
Meaningofvariablesfortheshallowwaterequation.
(
hv
\
t
+(
hv
2
+
1
2
gh
2
\
x
=0
:
(2.3\
One-dimensionalshallowwatersystemconsistsofthecontinuityequation(2.1\andthe
momentumequation(2.3\Weusethetwo-dimensionalshallowwaterequationwhosederiva-
tioncanbefoundin[3].
Itcanbewrittenas
U
t
+
F
(
U
\
x
+
G
(
U
\
y
=
S;
(2.4\
where
U
=
2
4
h
hu
hv
3
5
=
2
4
u
1
u
2
u
3
3
5
;
F
(
U
\=
2
4
hu
hu
2
+
1
2
gh
2
huv
3
5
=
2
4
u
2
u
2
2
=u
1
+
1
2
gu
2
1
u
2
u
3
u
1
3
5
;
G
(
U
\=
2
4
hv
huv
hv
2
+
1
2
gh
2
3
5
=
2
4
u
3
u
2
u
3
u
1
u
2
3
=u
1
+
1
2
gu
2
1
3
5
;
S
=
2
4
0
\241
ghb
x
\241
ghb
y
3
5
:
Here
h
=
h
(
x;y
\
denotesthedepthofwateroverthebottomtopography
b
=
b
(
x;y
\
,
u
,
v
arevelocitiesin
x
and
y
directions,and
g
standsforthegravitationalconstant(seeFigure
2.1\
3.Numericalsolution.
Weusedthree\002nitedifferencemethodsforconservationlaws,
theLax-Friedrichs(LF\theLax-Wendroff(LW\andtheMacCormack(MC\schemes.For
details,wereferthereaderto[4],[5].Allofthesemethodshavesomelimitations.TheLF
schemeis\002rst-order-accurateanddiffusive.TheLWandMCschemesaresecond-order-
accurate,butoscillatorynearshocks.

Parallelalgorithmfornumericalsolutionofproblemsin\003uiddynamics
27
Wethereforealsotestedthecompositeschemeaswellwhichcombinesthesemethods
inordertoeliminatetheirproblems.Formoreinformationaboutthecompositeschemes,see
[6],[7].Allcomputationsweremadewiththecompositeschemethatwasacompositionof
threeLWstepsandonediffusiveLFstepneededforremovingspuriousoscillations.
Theschemesinthefollowingsectionsarebasedonthe\002nitevolumeand\002nitedifference
discretization.
3.1.Lax-Friedrichsscheme.
Finitevolumemethodyields:
U
n
+1
i
=
1
N
N
X
k
=1
U
n
k
\241
\242
t
\271
(
D
i
\
N
X
k
=1
F
n
i;k
\242
y
k
\241
G
n
i;k
\242
x
k
;
(3.1\
where
F
n
i;k
=
1
2
[
F
(
U
n
i
\+
F
(
U
n
k
\
G
n
i;k
=
1
2
[
G
(
U
n
i
\+
G
(
U
n
k
\
:
(3.2\
Finitedifferencemethodyields:
U
n
+1
i;j
=
1
4
(
U
n
i;j
\241
1
+
U
n
i;j
+1
+
U
n
i
\241
1
;j
+
U
n
i
+1
;j
\
\241
k
2
h
\243
F
(
U
n
i
+1
;j
\
\241
F
(
U
n
i
\241
1
;j
\
\244
\241
k
2
l
\243
G
(
U
n
i;j
+1
\
\241
G
(
U
n
i;j
\241
1
\
\244
:
(3.3\
3.2.Lax-Wendroffscheme.
Finitevolumemethodyields:
U
n
+
1
2
i
=
1
N
N
X
k
=1
U
n
k
\241
\242
t
2
\271
(
D
i
\
N
X
k
=1
F
n
i;k
\242
y
k
\241
G
n
i;k
\242
x
k
;
U
n
+1
i
=
U
n
i
\241
\242
t
\271
(
D
i
\
N
X
k
=1
F
n
+
1
2
i;k
\242
y
k
\241
G
n
+
1
2
i;k
\242
x
k
;
(3.4\
where
F
n
i;k
=
1
2
[
F
(
U
n
i
\+
F
(
U
n
k
\
;F
n
+
1
2
i;k
=
1
2
[
F
(
U
n
+
1
2
i
\+
F
(
U
n
+
1
2
k
\
;
G
n
i;k
=
1
2
[
G
(
U
n
i
\+
G
(
U
n
k
\
;G
n
+
1
2
i;k
=
1
2
[
G
(
U
n
+
1
2
i
\+
G
(
U
n
+
1
2
k
\
:
(3.5\
Finite-differencemethodyields:
U
n
+
1
2
i;j
=
1
4
(
U
n
i;j
\241
1
+
U
n
i;j
+1
+
U
n
i
\241
1
;j
+
U
n
i
+1
;j
\
\241
k
4
h
[(
F
(
U
n
i
+1
;j
\
\241
F
(
U
n
i
\241
1
;j
\
\241
k
4
l
[(
G
(
U
n
i;j
+1
\
\241
G
(
U
n
i;j
\241
1
\
U
n
+1
i;j
=
U
n
i;j
\241
k
2
h
[(
F
(
U
n
+
1
2
i
+1
;j
\
\241
F
(
U
n
+
1
2
i
\241
1
;j
\
\241
k
2
l
[(
G
(
U
n
+
1
2
i;j
+1
\
\241
G
(
U
n
+
1
2
i;j
\241
1
\
:
(3.6\

28
S.Brand
3.3.MacCormackschemes.
Finitevolumemethodyields:
U
n
+
1
2
i
=
U
n
i
\241
\242
t
\271
(
D
i
\
N
X
k
=1
F
n
i;k
\242
y
k
\241
G
n
i;k
\242
x
k
;
U
n
+1
i
=
1
2
"
U
n
i
+
U
n
+
1
2
i
\241
\242
t
\271
(
D
i
\
N
X
k
=1
F
n
+
1
2
i;k
\242
y
k
\241
G
n
+
1
2
i;k
\242
x
k
#
;
(3.7\
where
F
n
i;
1
=
F
(
U
n
i
+1
;j
\
;F
n
i;
2
=
F
(
U
n
i;j
+1
\
;F
n
i;
3
=
F
n
i;
4
=
F
(
U
n
i;j
\
F
n
+
1
2
i;
3
=
F
(
U
n
+
1
2
i
\241
1
;j
\
;F
n
+
1
2
i;
4
=
F
(
U
n
+
1
2
i;j
\241
1
\
;F
n
+
1
2
i;
1
=
F
n
+
1
2
i;
2
=
F
(
U
n
+
1
2
i;j
\
G
n
i;
1
=
G
(
U
n
i
+1
;j
\
;G
n
i;
2
=
G
(
U
n
i;j
+1
\
;G
n
i;
3
=
G
n
i;
4
=
G
(
U
n
i;j
\
G
n
+
1
2
i;
3
=
G
(
U
n
+
1
2
i
\241
1
;j
\
;G
n
+
1
2
i;
4
=
G
(
U
n
+
1
2
i;j
\241
1
\
;G
n
+
1
2
i;
1
=
G
n
+
1
2
i;
2
=
G
(
U
n
+
1
2
i;j
\
:
(3.8\
Finitedifferencemethodyields:
U
n
+
1
2
i;j
=
U
n
i;j
\241
k
h
[(
F
(
U
n
i
+1
;j
\
\241
f
(
U
n
i;j
\
\241
k
h
[(
G
(
U
n
i;j
+1
\
\241
G
(
U
n
i;j
\
U
n
+1
i;j
=
1
2
(
U
n
i;j
+
U
n
+
1
2
i;j
\
\241
k
2
h
[(
F
(
U
n
+
1
2
i;j
\
\241
F
(
U
n
+
1
2
i
\241
1
;j
\
\241
k
2
h
[(
G
(
U
n
+
1
2
i;j
\
\241
G
(
U
n
+
1
2
i;j
\241
1
\
:
(3.9\
4.Stability.
Eachnumericalschememustsatisfythenecessarystabilityconditionin
theform
\242
t
\267
1
\275
A
\242
x
+
\275
B
\242
y
;
(4.1\
where
\275
A
and
\275
A
arespectralradiiofjacobianmatrix
A
and
B
,
A
=
@F
(
U
\
@U
=
2
4
010
gh
\241
u
2
2
u
0
\241
uvvu
3
5
;
(4.2\
B
=
@G
(
U
\
@U
=
2
4
001
\241
uvvu
gh
\241
v
2
02
v
3
5
:
(4.3\
Unfortunately,thisconditionisnotsuf\002cientfornonlinearpartialdifferentialequations.
Todemonstratestabilityandconsistency,wehavetousenumericalresultscomputedona
re\002nedgrid.Welinearlyinterpolatethesolutiononthe\002nestgridandcompareitwiththe
remainingsolutions(seeTables4.1-4.4\
5.Numericalresults.
Thissectioncontainsresultsfortheshallowwaterequationwith
the\003atbottom.Resultsarerepresentedbygraphsdisplayingdepthofwater
h
ateachpoint
ofthespacedomain(seeFigures5.1-5.3\Theinitialconditionforthedepthofwater

Parallelalgorithmfornumericalsolutionofproblemsin\003uiddynamics
29
Mesh
L
1
(0
;T
;
L
2
\
L
1
(0
;T
;
L
1
\
h
errorof
u
errorof
u
0.0800000
0.0154219
0.0149480
0.0400000
0.0078344
0.0071600
0.0200000
0.0036292
0.0033470
0.0100000
0.0015629
0.0016555
0.0050000
0.0005506
0.0006410
T
ABLE
4.1
TableofconvergenceerrorsfortheMacCormackscheme.
Mesh
EOC
u
EOC
u
h
L
2
L
1
0.0800000
0.0000000
0.0000000
0.0400000
0.9584786
1.2418251
0.0200000
1.3806293
1.0897255
0.0100000
0.9930047
1.1842024
0.0050000
1.0094179
1.2039963
T
ABLE
4.2
TableofEOCcoef\002cientsfortheMacCormackscheme.
Mesh
L
1
(0
;T
;
L
2
\
L
1
(0
;T
;
L
1
\
h
errorof
u
errorof
u
0.0800000
0.0154219
0.0149480
0.0400000
0.0078344
0.0071600
0.0200000
0.0036292
0.0033470
0.0100000
0.0015629
0.0016555
0.0050000
0.0005506
0.0006410
T
ABLE
4.3
Tableofconvergenceerrorsforthecompositescheme.
Mesh
EOC
u
EOC
u
h
L
2
L
1
0.0800000
0.0000000
0.0000000
0.0400000
0.9770784
1.0619210
0.0200000
1.1101687
1.0970910
0.0100000
1.2154725
1.0156016
0.0050000
1.5051878
1.3688708
T
ABLE
4.4
TableofEOCcoef\002cientsforthecompositescheme.
h
ispresentedin\002guresattime
t
=0
.Theinitialvelocities
u
,
v
weresettozero.The
solutionwascomputedatthetimeinterval
[0
;
0
:
14]
usingthespacedomain
[
\241
2
;
2]
\243
[
\241
2
;
2]
.
Weusetransmissiveandre\003ectiveboundaryconditionsatpoints
U
b
ontheboundary.The
transmissiveboundaryconditionarede\002nedas
U
b
=[
h;uh;vh
]
T
andthere\003ectiveonesare
de\002nedas
U
b
=[
h;
0
;
0]
T
,where
h;u;v
arevaluesattheinnerneighbourofeachboundary
point.

30
S.Brand
Shallowwater,t=0.0
0.8
0.6
0.4
2
1
0
-1
-2
2
1
0
-1
-2
Shallowwater,t=0.02
0.8
0.6
0.4
2
1
0
-1
-2
2
1
0
-1
-2
Shallowwater,t=0.04
0.8
0.6
0.4
2
1
0
-1
-2
2
1
0
-1
-2
Shallowwater,t=0.06
0.8
0.6
0.4
2
1
0
-1
-2
2
1
0
-1
-2
Shallowwater,t=0.08
0.8
0.6
0.4
2
1
0
-1
-2
2
1
0
-1
-2
Shallowwater,t=0.10
0.8
0.6
0.4
2
1
0
-1
-2
2
1
0
-1
-2
Shallowwater,t=0.12
0.8
0.6
0.4
2
1
0
-1
-2
2
1
0
-1
-2
Shallowwater,t=0.14
0.8
0.6
0.4
2
1
0
-1
-2
2
1
0
-1
-2
F
IG
.5.1
.
Shallowwater,transmissiveboundarycondition.

Parallelalgorithmfornumericalsolutionofproblemsin\003uiddynamics
31
Shallowwater,t=0.0
0.8
0.6
0.4
2
1
0
-1
-2
2
1
0
-1
-2
Shallowwater,t=0.02
0.8
0.6
0.4
2
1
0
-1
-2
2
1
0
-1
-2
Shallowwater,t=0.04
0.8
0.6
0.4
2
1
0
-1
-2
2
1
0
-1
-2
Shallowwater,t=0.06
0.8
0.6
0.4
2
1
0
-1
-2
2
1
0
-1
-2
Shallowwater,t=0.08
0.8
0.6
0.4
2
1
0
-1
-2
2
1
0
-1
-2
Shallowwater,t=0.10
0.8
0.6
0.4
2
1
0
-1
-2
2
1
0
-1
-2
Shallowwater,t=0.12
0.8
0.6
0.4
2
1
0
-1
-2
2
1
0
-1
-2
Shallowwater,t=0.14
0.8
0.6
0.4
2
1
0
-1
-2
2
1
0
-1
-2
F
IG
.5.2
.
Shallowwater,transmissiveboundarycondition.

32
S.Brand
Shallowwater,t=0.0
0.8
0.6
0.4
2
1
0
-1
-2
2
1
0
-1
-2
Shallowwater,t=0.02
0.8
0.6
0.4
2
1
0
-1
-2
2
1
0
-1
-2
Shallowwater,t=0.04
0.8
0.6
0.4
2
1
0
-1
-2
2
1
0
-1
-2
Shallowwater,t=0.06
0.8
0.6
0.4
2
1
0
-1
-2
2
1
0
-1
-2
Shallowwater,t=0.08
0.8
0.6
0.4
2
1
0
-1
-2
2
1
0
-1
-2
Shallowwater,t=0.10
0.8
0.6
0.4
2
1
0
-1
-2
2
1
0
-1
-2
Shallowwater,t=0.12
0.8
0.6
0.4
2
1
0
-1
-2
2
1
0
-1
-2
Shallowwater,t=0.14
0.8
0.6
0.4
2
1
0
-1
-2
2
1
0
-1
-2
F
IG
.5.3
.
Shallowwater,re\003ectiveboundarycondition.

Parallelalgorithmfornumericalsolutionofproblemsin\003uiddynamics
33
F
IG
.6.1
.
Usedsplittingofthespacedomain.
6.Parallelizationofnumericalalgorithms.
Themainpurposeofourworkwasto
comparetheef\002ciencyofparallelalgorithmsfornumericalsolutionoftheshallowwater
equationonsystemswithsharedmemory.Parallelcomputationisbasedonconceptsfor
dataexchange,sharedanddistributedmemory.Sharedmemorymeansthatalldataaresaved
inthememorythatcanbeaccessedbyallCPUs.ThisconceptisusedbyOpenMPAPI
(see[2]\Distributedmemorymeansthatinamultiprocessorsystemeachprocessorhas
itsownmemoryandaftertheprocessingofrequiredcomputationtasksthedatahavetobe
reassembled.ThisconceptisusedbyMessagePassingInterface(MPI\(see[1]\andisapplied
similarlyto[8].
Allthepresentednumericalschemesareexplicit.Thisenablestosplitthespacedomain
into
p
partsandsolveeachpartononeprocessingunit.TheOpenMPsharesthememory,
therefore,aftercomputingvaluesattime
n
,allCPUsstartcomputingthe
n
+1
timelevel.
However,withdistributedmemorysystems,itisnecessarytosendvaluesfromtheboundary
ofeachparttoallneighborsaftercompletingeverytimestepcomputation.
ThedomainsplittingisillustratedinFigure6.1,wherethesquarerepresentstheborder
ofthespacedomainanddashlinesrepresentbordersofpartsusedforthecomputationon
eachprocessingunit.Itcanbeseenthateachmiddleparthasonlytwoneighbors.This
simpli\002escommunicationneedsforparallelcomputation.Onecanadmitthatthissplittingis
notminimizingthenumberofdatasent.Forexample,ifweusethedomainsplittingwiththe
squareparts,thenwewillneedtosendonlytwothirdsofthedataneededforthiscase.But
thissplittingisindependentofthenumberofprocessingunits,whichallowustomeasurethe
ef\002ciencywiththesameprogramonanynumberofprocessors.
7.Resultsoftheef\002ciencymeasurement.
Theef\002ciencymeasurementwasperformed
fortheshallowwaterequation(2.4\onthefollowingparallelsystems.The\002rstthreecom-
putersaresharedmemoryparallelsystemsandthelasttwocomputersaredistributedparallel
systems.
\262
HewlettPackardC8000,4xCPUHPPA-RISC-1GHz,12GBRAM
\262
SGIALTIX3700,24xCPUIntelItaniumII-1,3GHz,64GBRAM
\262
LinuxPC,2xCPUIntelPentiumII-700MHz,1GBRAM
\262
Linuxgrid,8xCPUIntelPentium4-2.4GHz,512MBRAM
\262
Linuxgrid,12xCPUIntelPentium4-2.4GHz,512MBRAM
Theresultsofef\002ciencymeasurementarepresentedinTables7.1and7.1.Thetables
havethefollowingstructure.The\002rstcolumncontainsthegriddimension.Thesecond

34
S.Brand
columncontainsthetimeofsequenceprograminseconds,thismeansthetimeofthecompu-
tationmadebyonlyoneprocessingunit.Theremainingcolumnscontainthetimeofparallel
programandtheef\002ciencyofthisprograminthebrackets.Intheheaderofthesecolumns
thereisspeci\002edhowmanyMPIandOpenMPprocesseswereusedinthecomputation.The
timedurationofeachcomputationwasmeasuredbytheC
gettimeofday
(\
functionasa
differencebetweenthestartandtheendtime.Thetimeslistedinherearethetimesneeded
forthecomputationonly.Thismeansthetimesneededforthevalueinitializationandresult
savingisexcluded.Theef\002ciencyiscalculatedfromthefollowingformula:
e\261ciency=
sequencetime
paralleltime
\243
numberofprocessors
(7.1\
grid
OMP=4,MPI=1
OMP=2,MPI=2
OMP=1,MPI=4
100
\243
100
0.660
0.661(0.250\
0.249(0.664\
0.262(0.631\
200
\243
200
5.705
1.704(0.837\
1.833(0.778\
1.540(0.926\
300
\243
300
19.436
5.445(0.892\
5.525(0.879\
5.283(0.920\
400
\243
400
46.568
12.432(0.936\
12.564(0.927\
12.411(0.938\
500
\243
500
89.915
25.429(0.884\
24.972(0.900\
23.695(0.949\
600
\243
600
154.264
43.074(0.895\
42.324(0.911\
40.290(0.957\
700
\243
700
248.072
66.403(0.934\
66.086(0.938\
63.709(0.973\
800
\243
800
369.939
97.479(0.949\
95.952(0.964\
94.033(0.984\
900
\243
900
533.809
138.156(0.966\
139.469(0.957\
134.933(0.989\
1000
\243
1000
726.617
194.368(0.935\
190.263(0.955\
183.260(0.991\
1100
\243
1100
960.135
252.363(0.951\
248.010(0.968\
244.049(0.984\
1200
\243
1200
1250.901
327.944(0.954\
322.275(0.970\
319.292(0.979\
1300
\243
1300
1600.657
432.835(0.925\
429.117(0.933\
408.119(0.981\
1400
\243
1400
1975.505
530.362(0.931\
523.026(0.944\
506.207(0.976\
1500
\243
1500
2432.951
639.059(0.952\
635.187(0.958\
626.386(0.971\
1600
\243
1600
2918.703
762.497(0.957\
754.847(0.967\
753.314(0.969\
1700
\243
1700
3562.641
943.562(0.944\
931.938(0.956\
914.391(0.974\
1800
\243
1800
4169.705
1142.250(0.913\
1139.587(0.915\
1078.108(0.967\
1900
\243
1900
4900.167
1289.412(0.950\
1278.466(0.958\
1269.950(0.965\
2000
\243
2000
5668.034
1513.491(0.936\
1495.630(0.947\
1462.494(0.969\
T
ABLE
7.1
Timeandef\002ciencyofparallelprogramusingcompositeschemecomputedonsugar.fj\002.cvut.cz.
OMP=1,MPI=4
OMP=2,MPI=2
OMP=4,MPI=1
OMP=1,MPI=1
computationtime
2000150010005000
6000
5000
4000
3000
2000
1000
0
OMP=1,MPI=4
OMP=2,MPI=2
OMP=4,MPI=1
OMP=1,MPI=1
ef\002ciency
2000150010005000
2
1.5
1
0.5
0

Parallelalgorithmfornumericalsolutionofproblemsin\003uiddynamics
35
grid
OMP=2,MPI=1
OMP=1,MPI=2
100
\243
100
0.660
0.407(0.812\
0.350(0.943\
200
\243
200
5.705
2.979(0.957\
3.018(0.945\
300
\243
300
19.436
10.542(0.922\
10.168(0.956\
400
\243
400
46.568
23.888(0.975\
24.081(0.967\
500
\243
500
89.915
47.564(0.945\
46.331(0.970\
600
\243
600
154.264
78.828(0.978\
78.992(0.976\
700
\243
700
248.072
128.731(0.964\
125.554(0.988\
800
\243
800
369.939
185.831(0.995\
187.054(0.989\
900
\243
900
533.809
274.079(0.974\
267.076(0.999\
1000
\243
1000
726.617
364.812(0.996\
365.749(0.993\
1100
\243
1100
960.135
490.989(0.978\
484.739(0.990\
1200
\243
1200
1250.901
629.919(0.993\
632.366(0.989\
1300
\243
1300
1600.657
815.476(0.981\
809.857(0.988\
1400
\243
1400
1975.505
994.999(0.993\
1002.577(0.985\
1500
\243
1500
2432.951
1240.065(0.981\
1238.091(0.983\
1600
\243
1600
2918.703
1470.887(0.992\
1484.173(0.983\
1700
\243
1700
3562.641
1809.891(0.984\
1799.128(0.990\
1800
\243
1800
4169.705
2101.875(0.992\
2113.957(0.986\
1900
\243
1900
4900.167
2491.581(0.983\
2485.624(0.986\
2000
\243
2000
5668.034
2858.638(0.991\
2891.638(0.980\
T
ABLE
7.2
Timeandef\002ciencyofparallelprogramusingcompositeschemecomputedonsugar.fj\002.cvut.cz.
OMP=1,MPI=2
OMP=2,MPI=1
OMP=1,MPI=1
computationtime
2000150010005000
6000
5000
4000
3000
2000
1000
0
OMP=1,MPI=2
OMP=2,MPI=1
OMP=1,MPI=1
ef\002ciency
2000150010005000
2
1.5
1
0.5
0
8.Conclusion.
Theef\002ciencyresultsshowthatbothOpenMPandMPIaresuitablefor
parallelingprogramscomputingnumericalsolutionoftheshallowwaterequationbecauseits
valuesforthegridthatwaslargeenoughwereneverlessthan85%duringthetesting.Fora
smallgridtherethecommunicationtimeishigherthantheprocessingtimeandthereforethe
ef\002ciencyistoosmall.Oneimportantresultisthatef\002ciencyoftheprogramusingMPIwas
higherthanef\002ciencyoftheprogramusingOpenMP.Thisisduetotheidealconditionsover
themeasuring.Anyloadofoneprocessingunitwillenlargethecomputationaltimeofthe
programusingMPIwhiletheprogramusingOpenMPwillbeminimallyaffected.OpenMP
containsbuilt-intoolsforloadbalancingthatcanbeeasilyusedeveniftheprogrammerdid
notoriginallyintendtouseit.TheMPIprogrammerhastowritehisownloadbalancing
whichwillenlargetheprogrammingtime.

36
S.Brand
Acknowledgment.
TheworkwaspartlysupportedbytheprojectNo.LC06052\224Jind
\020
rich
Ne
\020
casCenterforMathematicalModelling\224oftheMinistryofEducation,YouthandSports
oftheCzechRepublic.
REFERENCES
[1]
MPI:AMessage-PassingInterfaceStandard
.http://www.mpi-forum.org/docs/mpi-11-html/mpi-report.html.
[2]
OpenMPApplicationProgramInterface
.http://www.openmp.org/drupal/mp-documents/spec25.pdf.
[3]
D.L.G
EORGE
,
NumericalApproximationoftheNonlinearShallowWaterEguationswithTopographyand
DryBeds:AGodunov-TypeScheme
.UniversityofWashington,Washington(2004\MasterTheses.
[4]
R.J.L
E
V
EQUE
,
NumericalMethodsforConservationLaws
.BirkhauserVerlag,Basel(1990\
[5]
R.J.L
E
V
EQUE
,
NonlinearConservationLawsandFiniteVolumeMethodsforAstrophysicalFluidFlow
.
Springer-Verlag,UniversityofWashington(1998\
[6]
R.L
ISKA
,
AND
B.W
ENDROFF
,
CompositeSchemesforConservationLaws
.SIAMJ.Numer.Anal.
35
,no.6
(1998\2250\2262271,.
[7]
R.L
ISKA
,
AND
B.W
ENDROFF
,
2DShallowWaterEquationsbyCompositeSchemes
.Int.J.Numerical
MethodsinFluids
30
(1999\461\226479.
[8]
M.
\020
S
ENK
\264
Y
\020
R
,J.M
IKY
\020
SKA
,
AND
M.B
ENE
\020
S
,ApplicationofParallelComputingTechniquesforProblems
ofDegenerateDiffusion.In
NumericalMathematicsandAdvancedApplications,ENUMATH2003(peer
reviewedproceedings\
,pages756\226766,SpringerVerlag,Berlin,2004.eds.M.Feistauer,VDolej
\020
s
\264
\021,P.
Knobloch,K.Najzar,ISBN3-540-21460-7.
